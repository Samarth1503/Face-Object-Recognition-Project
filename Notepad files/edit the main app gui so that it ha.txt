edit the main app gui so that it has only one button 'Start Regcognition' and once 'Start Regcognition' is clicked, it becomes 'Quit'. Also make sure that the close 'x' and others of the GUI work correctly.

app.py:
import cv2
import numpy as np
import face_recognition
import os
import tkinter as tk
from tkinter import Label, Button
from PIL import Image, ImageTk

# Load object recognition model
prototxt_path = "models/MobileNetSSD_deploy.prototxt"
model_path = "models/mobilenet_iter_73000.caffemodel"
net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)

# Class labels for object detection
CLASSES = ["background", "aeroplane", "bicycle", "bird", "boat", "bottle",
           "bus", "car", "cat", "chair", "cow", "diningtable", "dog", "horse",
           "motorbike", "person", "pottedplant", "sheep", "sofa", "train", "tvmonitor"]

# Load known faces
FACES_DIR = "data/faces"
def load_known_faces():
    known_encodings = []
    known_names = []
    for filename in os.listdir(FACES_DIR):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            img_path = os.path.join(FACES_DIR, filename)
            image = face_recognition.load_image_file(img_path)
            encoding = face_recognition.face_encodings(image)
            if encoding:
                known_encodings.append(encoding[0])
                known_names.append(os.path.splitext(filename)[0])
    return known_encodings, known_names

known_encodings, known_names = load_known_faces()

# Initialize Tkinter GUI
root = tk.Tk()
root.title("Face and Object Recognition App")
root.geometry("800x600")

video_label = Label(root)
video_label.pack()

result_label = Label(root, text="Recognition Results", font=("Arial", 14))
result_label.pack()

cap = cv2.VideoCapture(0)

def update_frame():
    ret, frame = cap.read()
    if not ret:
        return
    
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_locations = face_recognition.face_locations(rgb_frame)
    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)
    
    for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):
        matches = face_recognition.compare_faces(known_encodings, face_encoding)
        name = "Unknown"
        if True in matches:
            match_index = np.argmin(face_recognition.face_distance(known_encodings, face_encoding))
            name = known_names[match_index]
        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
    
    blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)
    net.setInput(blob)
    detections = net.forward()
    h, w = frame.shape[:2]
    
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > 0.5:
            class_id = int(detections[0, 0, i, 1])
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (startX, startY, endX, endY) = box.astype("int")
            label = CLASSES[class_id]
            cv2.rectangle(frame, (startX, startY), (endX, endY), (255, 0, 0), 2)
            cv2.putText(frame, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
            result_label.config(text=f"Detected: {label}")
    
    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    img = ImageTk.PhotoImage(img)
    video_label.imgtk = img
    video_label.config(image=img)
    root.after(10, update_frame)

start_button = Button(root, text="Start Recognition", command=update_frame)
start_button.pack()

quit_button = Button(root, text="Quit", command=root.quit)
quit_button.pack()

root.mainloop()
cap.release()
cv2.destroyAllWindows()